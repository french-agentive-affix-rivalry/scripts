{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the 5 DSMs\n",
    "\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "model1 = word2vec.KeyedVectors.load_word2vec_format('filepath/model1', binary=False, unicode_errors='ignore')\n",
    "model2 = word2vec.KeyedVectors.load_word2vec_format('filepath/model2', binary=False, unicode_errors='ignore')\n",
    "model3 = word2vec.KeyedVectors.load_word2vec_format('filepath/model3', binary=False, unicode_errors='ignore')\n",
    "model4 = word2vec.KeyedVectors.load_word2vec_format('filepath/model4', binary=False, unicode_errors='ignore')\n",
    "model5 = word2vec.KeyedVectors.load_word2vec_format('filepath/model5', binary=False, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the data\n",
    "\n",
    "import re\n",
    "fileData = open('filepath/file')\n",
    "\n",
    "listData = []\n",
    "\n",
    "for Line in fileData:\n",
    "    Line = Line.rstrip('\\n')\n",
    "    listData.append(Line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the 100 nearest neighbors to a centroid over 5 DSMs\n",
    "\n",
    "import numpy \n",
    "import re\n",
    "vector1 = numpy.zeros(100)\n",
    "vector2 = numpy.zeros(100)\n",
    "vector3 = numpy.zeros(100)\n",
    "vector4 = numpy.zeros(100)\n",
    "vector5 = numpy.zeros(100)\n",
    "\n",
    "n_items=0\n",
    "\n",
    "for mCat in listData:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        vector1 = numpy.add(vector1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        vector2 = numpy.add(vector2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        vector3 = numpy.add(vector3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        vector4 = numpy.add(vector4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        vector5 = numpy.add(vector5,m5_vector)\n",
    "        n_items += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "vector1 = numpy.divide(vector1,n_items)\n",
    "vector2 = numpy.divide(vector2,n_items)\n",
    "vector3 = numpy.divide(vector3,n_items)\n",
    "vector4 = numpy.divide(vector4,n_items)\n",
    "vector5 = numpy.divide(vector5,n_items)\n",
    "\n",
    "listVec = {}\n",
    "\n",
    "OrderedDict = {}\n",
    "for m in model1.vocab:\n",
    "    if m in model2.vocab and m in model3.vocab and m in model4.vocab and m in model5.vocab:\n",
    "        try:\n",
    "            val1 = abs(numpy.divide(numpy.dot(model1[m.strip()],vector1),numpy.dot(numpy.linalg.norm(model1[m.strip()]),numpy.linalg.norm(vector1))))\n",
    "            val2 = abs(numpy.divide(numpy.dot(model2[m.strip()],vector2),numpy.dot(numpy.linalg.norm(model2[m.strip()]),numpy.linalg.norm(vector2))))\n",
    "            val3 = abs(numpy.divide(numpy.dot(model3[m.strip()],vector3),numpy.dot(numpy.linalg.norm(model3[m.strip()]),numpy.linalg.norm(vector3))))\n",
    "            val4 = abs(numpy.divide(numpy.dot(model4[m.strip()],vector4),numpy.dot(numpy.linalg.norm(model4[m.strip()]),numpy.linalg.norm(vector4))))\n",
    "            val5 = abs(numpy.divide(numpy.dot(model5[m.strip()],vector5),numpy.dot(numpy.linalg.norm(model5[m.strip()]),numpy.linalg.norm(vector5))))\n",
    "            aveVal = (val1+val2+val3+val4+val5)/5\n",
    "            aveVal = str(aveVal)\n",
    "            if not re.search(\"e-0\", aveVal):\n",
    "                listVec[m] = aveVal\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "        \n",
    "sorted_by_value = sorted(listVec.items(), reverse=True, key=lambda kv: kv[1])\n",
    "print(len(sorted_by_value))\n",
    "for i in range(0,100):\n",
    "    word = sorted_by_value[i]\n",
    "    lemme = word[0]\n",
    "    prox = word[1]\n",
    "    output = lemme+\"\\t\"+prox\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average proximity score of X-ITs with each other or to Y-ITs\n",
    "# The computation of proximity score s to Y-ITs requires the preliminary loading of Y-ITs (see 2nd cell) - listDataY below\n",
    "\n",
    "fileOut = open('filepath/file', \"a\")\n",
    "\n",
    "for vCat in listData:\n",
    "    n_items = 0\n",
    "    v = \"NC:\"+vCat\n",
    "    globalAveProx = 0\n",
    "    if v not in model1.vocab:\n",
    "        continue\n",
    "    for wCat in listData:\n",
    "#    for wCat in listDataY:\n",
    "        if not wCat is vCat:\n",
    "            w = \"NC:\"+wCat\n",
    "            if w not in model1.vocab:\n",
    "                continue\n",
    "            n_items +=1\n",
    "            prox1 = model1.similarity(v,w)\n",
    "            prox2 = model2.similarity(v,w)\n",
    "            prox3 = model3.similarity(v,w)\n",
    "            prox4 = model4.similarity(v,w)\n",
    "            prox5 = model5.similarity(v,w)\n",
    "            aveProx = (abs(prox1)+abs(prox2)+abs(prox3)+abs(prox4)+abs(prox5))/5\n",
    "            globalAveProx = globalAveProx + aveProx\n",
    "\n",
    "    globalAveProx = globalAveProx/n_items\n",
    "    line = v+\"\\t\"+str(globalAveProx)+\"\\n\"\n",
    "    fileOut.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of proximity score of two centroids X and Y\n",
    "# Requires the loading of the list of Y-data - listDataY below\n",
    "\n",
    "import numpy \n",
    "import re\n",
    "x_vector_m1 = numpy.zeros(100)\n",
    "x_vector_m2 = numpy.zeros(100)\n",
    "x_vector_m3 = numpy.zeros(100)\n",
    "x_vector_m4 = numpy.zeros(100)\n",
    "x_vector_m5 = numpy.zeros(100)\n",
    "\n",
    "y_vector_m1 = numpy.zeros(100)\n",
    "y_vector_m2 = numpy.zeros(100)\n",
    "y_vector_m3 = numpy.zeros(100)\n",
    "y_vector_m4 = numpy.zeros(100)\n",
    "y_vector_m5 = numpy.zeros(100)\n",
    "\n",
    "n_x=0\n",
    "n_y = 0\n",
    "\n",
    "for mCat in listData:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        x_vector_m1 = numpy.add(x_vector_m1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        x_vector_m2 = numpy.add(x_vector_m2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        x_vector_m3 = numpy.add(x_vector_m3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        x_vector_m4 = numpy.add(x_vector_m4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        x_vector_m5 = numpy.add(x_vector_m5,m5_vector)\n",
    "        n_x += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "x_vector_m1 = numpy.divide(x_vector_m1,n_x)\n",
    "x_vector_m2 = numpy.divide(x_vector_m2,n_x)\n",
    "x_vector_m3 = numpy.divide(x_vector_m3,n_x)\n",
    "x_vector_m4 = numpy.divide(x_vector_m4,n_x)\n",
    "x_vector_m5 = numpy.divide(x_vector_m5,n_x)\n",
    "        \n",
    "for mCat in listDataY:\n",
    "    m = \"NC:\"+mCat\n",
    "    try:\n",
    "        m1_vector = model1[m.strip()]\n",
    "        y_vector_m1 = numpy.add(y_vector_m1,m1_vector)\n",
    "        m2_vector = model2[m.strip()]\n",
    "        y_vector_m2 = numpy.add(y_vector_m2,m2_vector)\n",
    "        m3_vector = model3[m.strip()]\n",
    "        y_vector_m3 = numpy.add(y_vector_m3,m3_vector)\n",
    "        m4_vector = model4[m.strip()]\n",
    "        y_vector_m4 = numpy.add(y_vector_m4,m4_vector)\n",
    "        m5_vector = model5[m.strip()]\n",
    "        y_vector_m5 = numpy.add(y_vector_m5,m5_vector)\n",
    "        n_y += 1\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "y_vector_m1 = numpy.divide(y_vector_m1,n_y)\n",
    "y_vector_m2 = numpy.divide(y_vector_m2,n_y)\n",
    "y_vector_m3 = numpy.divide(y_vector_m3,n_y)\n",
    "y_vector_m4 = numpy.divide(y_vector_m4,n_y)\n",
    "y_vector_m5 = numpy.divide(y_vector_m5,n_y)\n",
    "        \n",
    "prox1 = abs(numpy.divide(numpy.dot(y_vector_m1,x_vector_m1),numpy.dot(numpy.linalg.norm(y_vector_m1),numpy.linalg.norm(x_vector_m1))))\n",
    "prox2 = abs(numpy.divide(numpy.dot(y_vector_m2,x_vector_m2),numpy.dot(numpy.linalg.norm(y_vector_m2),numpy.linalg.norm(x_vector_m2))))\n",
    "prox3 = abs(numpy.divide(numpy.dot(y_vector_m3,x_vector_m3),numpy.dot(numpy.linalg.norm(y_vector_m3),numpy.linalg.norm(x_vector_m3))))\n",
    "prox4 = abs(numpy.divide(numpy.dot(y_vector_m4,x_vector_m4),numpy.dot(numpy.linalg.norm(y_vector_m4),numpy.linalg.norm(x_vector_m4))))\n",
    "prox5 = abs(numpy.divide(numpy.dot(y_vector_m5,x_vector_m5),numpy.dot(numpy.linalg.norm(y_vector_m5),numpy.linalg.norm(x_vector_m5))))\n",
    "proxM = (prox1+prox2+prox3+prox4+prox5)/5\n",
    "print(proxM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
